use anyhow;
use futures::StreamExt;
use serde::{Deserialize, Serialize};
use sqlx::Row;
use std::sync::Arc;
use tauri::ipc::Channel;
use tracing::{debug, error, info};

use crate::models::chat::ChatMessagePair;
use crate::models::node_type::NodeType;
use crate::services::ai::AiService;
use crate::services::ai_client::{AIClient, ChatMessage};
use crate::services::chat_branch::ChatBranchService;
use crate::services::chat_node::{ChatNodeService, GetAllChatNodesParams, UpdateChatNodeParams};
use crate::services::chat_node_message::ChatNodeMessageService;
use crate::services::database::DbPool;
use crate::services::message_events::MessageEvent;
use crate::services::stream_registry::StreamRegistry;
use crate::utils::markdown::markdown_to_html;

/// Response for reconnect operation
#[derive(Debug, Serialize, Deserialize)]
pub enum ReconnectResponse {
    /// Successfully reconnected to active stream
    Success,
    /// No active stream found for the branch
    NoActiveStream,
}

/// Service responsible for generating messages and managing message-related operations
pub struct MessageGenerationService {
    pool: Arc<DbPool>,
    registry: Arc<StreamRegistry>,
    ai_client: AIClient,
    node_service: NodeService,
    node_message_service: NodeMessageService,
}

impl MessageGenerationService {
    /// Create a new message generation service with default configuration
    pub fn new(pool: Arc<DbPool>, node_service: NodeService) -> Self {
        debug!("Creating new MessageGenerationService with default AI client");
        let pool_clone = Arc::clone(&pool);
        Self {
            pool,
            registry: Arc::new(StreamRegistry::new()),
            ai_client: AIClient::new(),
            node_service,
            node_message_service: NodeMessageService::new(pool_clone),
        }
    }

    /// Send a user message and generate a response
    ///
    /// This function:
    /// 1. Inserts the user message as a new node with content
    /// 2. Creates an empty assistant node immediately
    /// 3. Returns both the user node and assistant node in a ChatMessagePair
    /// 4. Uses the provided channel for streaming AI responses
    pub async fn send_message(
        &self,
        branch_id: &str,
        message: &str,
        channel: Channel<MessageEvent>,
    ) -> sqlx::Result<ChatMessagePair> {
        info!("Processing message for branch ID: {}", branch_id);
        debug!("User message content: {}", message);
        debug!("Channel ID: {:?}", channel.id());

        // Insert the user message using the chat node service
        let user_node_id = self
            .node_service
            .create_node(
                branch_id,
                NodeType::UserMessage.as_str(),
                message,
                None, // No parent message
            )
            .await?;

        info!("Successfully added user message with ID: {}", user_node_id);

        // Create an empty assistant node immediately
        let assistant_node_id = self
            .node_service
            .create_node(
                branch_id,
                NodeType::AssistantMessage.as_str(),
                "",                  // Empty content initially
                Some(&user_node_id), // Parent is the user message
            )
            .await?;

        info!(
            "Created empty assistant node with ID: {}",
            assistant_node_id
        );

        // Check for an active stream
        if self.registry.get_stream(branch_id).await.is_some() {
            debug!(
                "Found existing stream for branch ID: {}, removing it",
                branch_id
            );
            // Remove the existing stream if there is one
            self.registry.remove_stream(branch_id).await;
        }

        // Add stream to registry
        debug!("Adding stream to registry for branch ID: {}", branch_id);
        self.registry.add_stream(branch_id, channel.clone()).await;

        // Start generating AI response in a separate task
        self.generate_ai_response(branch_id, message, &user_node_id, &assistant_node_id)
            .await;

        // Fetch both nodes to return
        let user_node = self.chat_node_service.get_node(&user_node_id).await?;
        let assistant_node = self.chat_node_service.get_node(&assistant_node_id).await?;

        debug!(
            "Returning ChatMessagePair with user_node: {:?}, assistant_node: {:?}",
            user_node, assistant_node
        );
        // Return both nodes as a pair
        Ok(ChatMessagePair {
            user_node,
            assistant_node,
        })
    }

    /// Regenerate a response for an existing message
    pub async fn regenerate_message(
        &self,
        node_id: &str,
        channel: Channel<MessageEvent>,
    ) -> sqlx::Result<()> {
        info!("Regenerating response for node ID: {}", node_id);

        let chat_node = self.chat_node_service.get_node(node_id).await?;
        let branch_id = chat_node.branch_id.clone();

        // Prevent regeneration if an active stream exists for this branch
        if self.registry.get_stream(&branch_id).await.is_some() {
            debug!(
                "Active stream exists for branch ID: {}, skipping regeneration",
                branch_id
            );

            return Ok(());
        }

        let mut tx = self.pool.get().begin().await?;

        let next_version_number = self
            .message_service
            .get_next_version_number_with_executor(&mut *tx, &chat_node.id)
            .await?;

        // Create a new version for the assistant node message and set as active
        let new_message = self
            .message_service
            .create_with_executor(
                &mut *tx,
                &chat_node.id,
                "",
                next_version_number,
                "generating",
            )
            .await?;

        // Clone before potential move
        let new_message_clone = new_message.clone();

        self.chat_node_service
            .update_with_executor(
                &mut *tx,
                node_id,
                UpdateChatNodeParams {
                    active_message_id: Some(new_message),
                    ..Default::default()
                },
            )
            .await?;

        tx.commit().await?;

        // Add stream to registry
        debug!("Adding stream to registry for branch ID: {}", branch_id);
        self.registry.add_stream(&branch_id, channel.clone()).await;

        // Clone necessary services and values before spawning task
        let chat_node_service = self.chat_node_service.clone();
        let ai_client = self.ai_client.clone();
        let node_id_clone = chat_node.id.clone();
        let new_message_clone = new_message_clone;
        let stream_registry_clone = self.registry.clone();
        let message_service_clone = self.message_service.clone();
        let pool = self.pool.clone();
        // NOTE: No more fallback to default integration/model/branch. If not found, log error and return early.

        tokio::spawn(async move {
            let result: anyhow::Result<()> = async {
                let nodes = chat_node_service
                    .get_all(GetAllChatNodesParams {
                        older_than: Some(node_id_clone.clone()),
                        branch_id: Some(branch_id.clone()),
                    })
                    .await?;

                let mut chat_history = vec![];

                for node in &nodes {
                    let type_: String = node.node_type.clone();
                    let content: String = node.active_message.as_ref().unwrap().content.clone();
                    let node_type = NodeType::from(type_);

                    if let Some(role) = node_type.to_role() {
                        chat_history.push(crate::services::ai_client::ChatMessage {
                            role: role.to_string(),
                            content: content,
                        });
                    }
                }

                // --- Fetch branch, model, and integration for dynamic config ---
                let chat_branch_service = ChatBranchService::new(pool.clone());
                let ai_service = AiService::new(pool.clone());
                let branch = chat_branch_service
                    .get_branch(&branch_id)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| anyhow::anyhow!("Branch not found for id: {}", branch_id))?;
                let model_id = branch
                    .model_id
                    .ok_or_else(|| anyhow::anyhow!("No model_id set for branch {}", branch_id))?;
                let model = ai_service
                    .get_model_by_id(&model_id)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| anyhow::anyhow!("Model not found for id: {}", model_id))?;
                let integration = ai_service
                    .get_integration(&model.integration_id)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| {
                        anyhow::anyhow!("Integration not found for id: {}", model.integration_id)
                    })?;
                let mut url = integration.host;
                if let Some(base_path) = integration.base_path {
                    url.push_str(&base_path);
                }
                if let Some(chat_path) = integration.chat_completion_path {
                    url.push_str(&chat_path);
                }
                // --- End dynamic config fetch ---
                // Define the expected response structure (adjust based on API)
                #[derive(serde::Deserialize, Debug)]
                struct AiResponseMessage {
                    role: String,
                    content: String,
                }
                #[derive(serde::Deserialize, Debug)]
                struct AiResponse {
                    // The actual message is now nested under the 'message' field
                    message: AiResponseMessage,
                    // Other fields are ignored for now, but can be added if needed
                }

                let mut stream = ai_client
                    .generate_chat_stream::<AiResponse>(url, model.model_id, chat_history)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?;

                let mut full_response = String::new();

                while let Some(result) = stream.next().await {
                    match result {
                        Ok(data) => {
                            // The content is now nested: data.message.content
                            let response_text = data.message.content;
                            full_response.push_str(&response_text);

                            if let Some(stream_channel) =
                                stream_registry_clone.get_stream(&branch_id).await
                            {
                                let html_response = markdown_to_html(&full_response);
                                stream_channel.send(MessageEvent::MessageReceived {
                                    message: html_response,
                                    node_id: node_id_clone.clone(),
                                    message_id: new_message_clone.clone(),
                                });
                            }
                        }
                        Err(e) => {
                            error!("Error processing response chunk: {:?}", e);
                            stream_registry_clone.remove_stream(&branch_id).await;
                            break;
                        }
                    }
                }

                stream_registry_clone.remove_stream(&branch_id).await;
                debug!("Full response: {}", full_response);
                message_service_clone
                    .update(&new_message_clone, &full_response)
                    .await;
                Ok(())
            }
            .await;
            if let Err(e) = result {
                // Always remove the stream from the registry on error to avoid stale streams
                stream_registry_clone.remove_stream(&branch_id).await;
                error!("regenerate_message task failed: {e}");
                // Optionally, update message status to error here
            }
        });

        Ok(())
    }

    /// Reconnect to an existing chat stream with a new channel
    ///
    /// This function:
    /// 1. Checks if there's an active stream for the given branch ID
    /// 2. If there is, replaces the channel in the registry and returns success
    /// 3. If not, returns a message indicating no active stream
    pub async fn reconnect(
        &self,
        branch_id: &str,
        channel: Channel<MessageEvent>,
    ) -> ReconnectResponse {
        debug!("Attempting to reconnect for branch ID: {}", branch_id);
        debug!("New channel ID: {:?}", channel.id());

        // Check if there's an active stream for this specific branch ID
        if self.registry.get_stream(branch_id).await.is_some() {
            info!(
                "Active stream found for branch ID: {}, replacing it",
                branch_id
            );

            // Remove the existing stream for this branch ID only
            self.registry.remove_stream(branch_id).await;

            // Add the new stream for this branch ID only
            self.registry.add_stream(branch_id, channel).await;

            ReconnectResponse::Success
        } else {
            info!("No active stream found for branch ID: {}", branch_id);
            ReconnectResponse::NoActiveStream
        }
    }

    /// Unregister an active stream for a branch
    pub async fn unregister_stream(&self, branch_id: &str) {
        self.registry.remove_stream(branch_id).await;
    }

    /// Generate an AI response in a separate task
    async fn generate_ai_response(
        &self,
        branch_id: &str,
        message: &str,
        user_node_id: &str,
        assistant_node_id: &str,
    ) {
        debug!("Starting AI response generation for branch: {}", branch_id);
        debug!("Message prompt: {}", message);
        debug!("User node ID: {}", user_node_id);
        debug!("Assistant node ID: {}", assistant_node_id);

        let branch_id_clone = branch_id.to_string();
        let registry_clone = self.registry.clone();
        let chat_node_service_clone = self.chat_node_service.clone();
        let message_service_clone = self.message_service.clone();
        let ai_client_clone = self.ai_client.clone();
        let assistant_node_id_clone = assistant_node_id.to_string();
        let user_node_id_clone = user_node_id.to_string();
        let pool = self.pool.clone();
        // NOTE: No more fallback to default integration/model/branch. If not found, log error and return early.
        let message_owned = message.to_string();
        tokio::spawn(async move {
            let result: anyhow::Result<()> = async {
                let nodes = chat_node_service_clone
                    .get_all(GetAllChatNodesParams {
                        older_than: Some(user_node_id_clone.clone()),
                        branch_id: Some(branch_id_clone.clone()),
                    })
                    .await?;

                let mut chat_history = vec![];

                for node in &nodes {
                    let type_: String = node.node_type.clone();
                    let content: String = node.active_message.as_ref().unwrap().content.clone();
                    let node_type = NodeType::from(type_);

                    if let Some(role) = node_type.to_role() {
                        chat_history.push(crate::services::ai_client::ChatMessage {
                            role: role.to_string(),
                            content: content,
                        });
                    }
                }

                chat_history.push(crate::services::ai_client::ChatMessage {
                    role: "user".to_string(),
                    content: message_owned,
                });

                // --- Fetch branch, model, and integration for dynamic config ---
                let chat_branch_service = ChatBranchService::new(pool.clone());
                let ai_service = AiService::new(pool.clone());
                let branch = chat_branch_service
                    .get_branch(&branch_id_clone)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| {
                        anyhow::anyhow!("Branch not found for id: {}", branch_id_clone)
                    })?;
                let model_id = branch.model_id.ok_or_else(|| {
                    anyhow::anyhow!("No model_id set for branch {}", branch_id_clone)
                })?;
                let model = ai_service
                    .get_model_by_id(&model_id)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| anyhow::anyhow!("Model not found for id: {}", model_id))?;
                let integration = ai_service
                    .get_integration(&model.integration_id)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?
                    .ok_or_else(|| {
                        anyhow::anyhow!("Integration not found for id: {}", model.integration_id)
                    })?;
                let mut url = integration.host;
                if let Some(base_path) = integration.base_path {
                    url.push_str(&base_path);
                }
                if let Some(chat_path) = integration.chat_completion_path {
                    url.push_str(&chat_path);
                }
                // --- End dynamic config fetch ---
                // Define the expected response structure (adjust based on API)
                #[derive(serde::Deserialize, Debug)]
                struct AiResponseMessage {
                    role: String,
                    content: String,
                }
                #[derive(serde::Deserialize, Debug)]
                struct AiResponse {
                    // The actual message is now nested under the 'message' field
                    message: AiResponseMessage,
                    // Other fields are ignored for now, but can be added if needed
                }

                let mut stream = ai_client_clone
                    .generate_chat_stream::<AiResponse>(url, model.model_id, chat_history)
                    .await
                    .map_err(|e| anyhow::anyhow!(e))?;

                let mut full_response = String::new();

                while let Some(result) = stream.next().await {
                    match result {
                        Ok(data) => {
                            debug!("Received JSON string: {}", data.message.content);
                            // The content is now nested: data.message.content
                            let response_text = data.message.content;
                            full_response.push_str(&response_text);

                            if let Some(stream_channel) =
                                registry_clone.get_stream(&branch_id_clone).await
                            {
                                let html_response = markdown_to_html(&full_response);

                                if let Err(e) = stream_channel.send(MessageEvent::MessageReceived {
                                    message: html_response,
                                    node_id: assistant_node_id_clone.clone(),
                                    message_id: String::new(),
                                }) {
                                    error!("Failed to send message through channel: {:?}", e);
                                    break;
                                }

                                registry_clone
                                    .append_to_history(&branch_id_clone, &response_text)
                                    .await;
                            }
                        }
                        Err(e) => {
                            error!("Error processing response chunk: {:?}", e);
                            break;
                        }
                    }
                }

                let current_assistant_node = chat_node_service_clone
                    .get_node(&assistant_node_id_clone)
                    .await?;

                registry_clone.remove_stream(&branch_id_clone).await;
                debug!("Full response: {}", full_response);

                // Unwrap the Option<String> to get a &str or skip if None
                if let Some(active_message_id) = &current_assistant_node.active_message_id {
                    message_service_clone
                        .update(active_message_id, &full_response)
                        .await?;
                }
                Ok(())
            }
            .await;
            if let Err(e) = result {
                // Always remove the stream from the registry on error to avoid stale streams
                registry_clone.remove_stream(&branch_id_clone).await;
                error!("generate_ai_response task failed: {e}");
                // Optionally, update message status to error here
            }
        });
    }

    /// Prepare chat history for AI generation
    async fn prepare_chat_history(
        chat_node_service: &ChatNodeService,
        branch_id: &str,
        message: &str,
    ) -> Vec<crate::services::ai_client::ChatMessage> {
        // Get all messages from the branch in chronological order (oldest first)
        // This will either return messages or panic on database errors
        let history_nodes = chat_node_service.get_branch_messages(branch_id).await;

        let mut chat_messages = Vec::new();
        for node in &history_nodes {
            let node_type: String = node.get("node_type");
            let content: String = node.get("content");
            let node_id: String = node.get("id");
            let token_count: Option<i64> = node.try_get("token_count").unwrap_or(None);

            let node_type = NodeType::from(type_);

            // Skip nodes that don't have a role defined (notes)
            if let Some(role) = node_type.to_role() {
                chat_messages.push(crate::services::ai_client::ChatMessage {
                    role: role.to_string(),
                    content: content.clone(),
                });
            }
        }

        chat_messages
    }
}

// Implement Clone for AIClient (reqwest::Client is Clone)
impl Clone for AIClient {
    fn clone(&self) -> Self {
        Self {
            http_client: self.http_client.clone(),
        }
    }
}
